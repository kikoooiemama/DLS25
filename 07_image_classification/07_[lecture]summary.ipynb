{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Лекция 1. Архитектуры CNN **<a href=\"https://www.youtube.com/watch?v=TcUPuKpIlhQ\">YouTube</a>**  **<a href=\"https://vkvideo.ru/video-155161349_456239232?ref_domain=stepik.org\">VK</a>**\n",
    "* Лекция 2. Transfer Learning **<a href=\"https://www.youtube.com/watch?v=oLpREso27Zw\">YouTube</a>**  **<a href=\"https://vkvideo.ru/video-155161349_456239233?ref_domain=stepik.org\">VK</a>**\n",
    "* Семинар 1. Продвинутое обучение свёрточных нейронных сетей **<a href=\"https://www.youtube.com/watch?v=cf5OFswrln0\">YouTube</a>**  **<a href=\"https://vkvideo.ru/video-155161349_456239234?ref_domain=stepik.org\">VK</a>**\n",
    "* Семинар 2. Transfer learning для задачи классификации изображений **<a href=\"https://www.youtube.com/watch?v=awgMvmJQUF0\">YouTube</a>**  **<a href=\"https://vkvideo.ru/video-155161349_456239235?ref_domain=stepik.org\">VK</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-h7yCBjzRAV"
   },
   "source": [
    "### 1. Архитектуры CNN\n",
    "Вспоминали как конкурс ImageNet показал эффективность нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCJQZXLtV-1q"
   },
   "source": [
    "#### 1.1 AlexNet\n",
    "\n",
    "- Выиграла конкурс ImageNet в 2012 году.\n",
    "\n",
    "Структура:\n",
    "- Input (227x227x3) - картинка с 3мя каналами.\n",
    "- Сильные фильтры: светрка 11х11, stride=3\n",
    "- CL1 (Convolution layer): 55x55x96\n",
    "- CL2: 27x27x256\n",
    "- CL3: 13x13x384\n",
    "Зачем нужна свертка 1x1? Для добавления нелинейности и для манипулирования количеством карт активаций.\n",
    "- CL4: 13x13x384\n",
    "- CL5: 13x13x256\n",
    "- FCL6: 4096 (Linear + ReLU)\n",
    "- FCL7: 4096 (Linear + ReLU)\n",
    "- FCL8: 1000 (Linear + SoftMax)\n",
    "\n",
    "Главные фишки: использование ReLU вместо Tanh, Data Augmentation, параллельное вычисление на GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8T2SseOPkjws"
   },
   "source": [
    "#### 1.2 VGG\n",
    "\n",
    "Более глубокая по сравнению с AlexNet. Все фильтры CL имеют размерность 3х3.\n",
    "Есть разные типы VGG в зависимости от количества сверточных слоев!\n",
    "\n",
    "Это схема VGG-16:\n",
    "\n",
    "<!-- <img src=\"https://drive.google.com/uc?id=1vHCNm-GbFfGva6XE8mrQ6RWLvaMgaCkl\"/> -->\n",
    "<img src=\"./img/vgg-19.png\"/>\n",
    "<br>\n",
    "\n",
    "- torchvision.models - хаб с готовыми моделями (в том числе vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbegSLUzp9E2"
   },
   "source": [
    "#### 1.3 Skip Connection (Прием для архитектуры)\n",
    "\n",
    "Решение проблемы затухающих градиентов. Мы пропускаем несколько слоев нейронной сети.\n",
    "\n",
    "<!-- <img src=\"https://drive.google.com/uc?id=1tYvbyK1eelQW3mFMxEYdT-LNSpOt3Bn0\"/> -->\n",
    "<img src=\"./img/sc_1.png\"/>\n",
    "<br>\n",
    "<!-- <img src=\"https://drive.google.com/uc?id=1x3YsLBcz3hjVEvLcbPMDT5Fcd6znASxR\"/> -->\n",
    "<img src=\"./img/sc_2.png\"/>\n",
    "<br>\n",
    "\n",
    "Таким образом веса обновляются более менее нормально, поскольку градиенты не затухают так сильно.\n",
    "\n",
    "- используется чаще всего в CNN (включая ResNet)\n",
    "- помогает в борьбе с затуханием градиентов\n",
    "- помогает “протолкнуть” в нижние слои сети информацию из верхних\n",
    "слоев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKMCd0utcDXK"
   },
   "source": [
    "#### 1.4 ResNet\n",
    "В ResNet как раз используется Skip Connection: __Residual blocks__. ResNet = CNN + skip connection (residual connection).\n",
    "- BN after addition\n",
    "- ReLU before addition\n",
    "- ReLU only pre-activation\n",
    "- full pre-activation\n",
    "\n",
    "<!-- <img src=\"https://drive.google.com/uc?id=1cpjibX9X_mKuAzyps02YBfjIzFEIszJS\"/> -->\n",
    "<img src=\"./img/resnet.png\"/>\n",
    "<br>\n",
    "\n",
    "- ResNet'ов также очень много вариаций, самые известные: 18, 34.\n",
    "\n",
    "Интересный факт: из ResNet можно выкинуть несколько слоев и ее performance снизится не слишком сильно. Это достигается тем, что у ResNet есть “обходные пути” для информации (skip-connection), и при прерывании одного из них информация все еще может пройти по другому"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CC6xpjqFfLlJ"
   },
   "source": [
    "#### 1.5 DenseNet\n",
    "\n",
    "DenseBlock: каждый последующий слой сети получает на вход все выходы всех предыдущих сетей.\n",
    "\n",
    "У него Dense блока есть параметр: growth rate - определяет насколько больше каждый сверточный слой будет получать карт активай по сравнению со своим предшественником.\n",
    "\n",
    "<!-- <img src=\"https://drive.google.com/uc?id=1qsbpM0E2nqg2kXok_nehDFxQybFsHXtg\"/> -->\n",
    "<img src=\"./img/densenet.png\"/>\n",
    "<br>\n",
    "\n",
    "- strong gradient flow (skip connection) - фиксим затухание градиентов.\n",
    "- количество слоев и параметров не очень большое\n",
    "- conv слои выделяют более разнообразные фичи\n",
    "То есть нижние conv слои принимают во внимание low-complex паттерны из более верхних слоев, которые могут быть полезны для детекции некоих low-level паттернов. Также это помогает DenseNet лучше обучаться на маленьких датасетах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kck_sbUDiSIg"
   },
   "source": [
    "#### Bottleneck Block\n",
    "\n",
    "ResNet и DenseNet состоят из блоков. Блоки, конечно, могут иметь разную архитектуру, не только ту, что мы рассматривали выше.\n",
    "\n",
    "<!-- <img src=\"https://drive.google.com/uc?id=1De3RawYCMcaHfhs4XrJBm08rN9fkMYw-\"/> -->\n",
    "<img src=\"./img/bottleneck.png\"/>\n",
    "<br>\n",
    "\n",
    "- Используются чтобы уменьшить размерность карт активаций и количество параметров, которые требуются нейронным сетям для обработки картинок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdO0YPjrkePp"
   },
   "source": [
    "#### 1.6 Inception\n",
    "\n",
    "Идея: сделать несколько сверточные слоев с разными размерами\n",
    "фильтров на одном уровне (параллельные conv).\n",
    "\n",
    "<!-- <img src=\"https://drive.google.com/uc?id=1aJExwnWhNhD-ULQ2l32Bwb8KPmyXNSnm\"/> -->\n",
    "<img src=\"./img/inception.png\"/>\n",
    "<br>\n",
    "\n",
    "- в Inception тоже есть затухающие градиенты, но их решают так: дополнительные классификаторы (3 головы на схеме, выделены желтым блоком). В данном случае 3 варианта результата сети, то есть 3 выхода. 3ой loss -> для более высоких слоев, будет приходить влияние из 3 мест и из самого первого выхода соответственно будут самые большие градиенты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtxLYiXAhDXj"
   },
   "source": [
    "#### 1.7 torchvision.models\n",
    "\n",
    "- AlexNet\n",
    "- VGG\n",
    "- ResNet\n",
    "- SqueezeNet\n",
    "- DenseNet\n",
    "- Inception v3\n",
    "- GoogleNet\n",
    "- ShuffleNet v2\n",
    "- MobileNet v2 - использует легковесные conv, экономя память и скорость.\n",
    "- ResNeXt\n",
    "- Wide ResNet\n",
    "- MNASNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cntXwLNoWPRJ"
   },
   "source": [
    "### 2. Transfer Learning\n",
    "\n",
    "Часто датасет под какую-либо задачу для обучения сети содержит\n",
    "мало объектов.\n",
    "И если обучать сеть на этом датасете с нуля, сеть переобучится.\n",
    "\n",
    "Пример: медицинские датасеты изображений опухолей, машинный\n",
    "перевод с малораспространенных языков (татарский), etc.\n",
    "\n",
    "Идея: использовать знания, полученные другими сетями на похожих задачах.\n",
    "\n",
    "Пример: заменили последний слой с 1000 выходами, на слой с 10 выходами, но при этом проблема с переобучением остается.\n",
    "\n",
    "Решение: Заморозка (Fine-Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uu5oeOcVaze0"
   },
   "source": [
    "#### 2.1 Fine-Tuning\n",
    "\n",
    "<!-- <img src=\"https://drive.google.com/uc?id=1ZqLFHzWA3MThyhFK56887XRBYH57IlFZ\"/> -->\n",
    "<img src=\"./img/freeze.png\"/>\n",
    "<br>\n",
    "\n",
    "- Замораживаются верхние (первые) слои сети, нижние дообучаются. Верхние слои выделяют низкоуровневую информацию, и они научились хорошо это делать при предобучении. Нижние слои выделяют из информации, полученной из верхних слоев, спецефическую для задачи информацию, поэтому их нужно дообучать.\n",
    "- Сколько слоев замораживать, заивисит от различия между датасетами, сложности задачи и объема датасета для дообучения.\n",
    "- Чем больше в target задаче тренировочных данных и чем сильнее source и target задачи отличаются между собой, тем больше слоев нужно дообучать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "484OvxdPgsCM"
   },
   "source": [
    "__Понятия Transfer Learning, Domain Adaptation и Multi-task Learning часто используются в одном контексте__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9K5JIbYiAkx"
   },
   "source": [
    "#### 2.2 Проблемы\n",
    "\n",
    "1. $D_s \\neq D_t$\n",
    "\n",
    "Пространства признаков двух доменов ーразные. Пример: в NLP два датасета текстов на двух разных языках. Например, датасеты MNIST и SVHN\n",
    "\n",
    "2. $P(D_s) \\neq P(D_t)$\n",
    "\n",
    "Распределения признаков в двух доменах разные. Такой TL называется Domain Adaptation. Пример: Датасет ревью на фильмы на Кинопоиске и датасет ревью на мобильные приложения в Google Play. И там, и там задача ー предсказать оценку ревью (от 0 до 5)\n",
    "\n",
    "3. $Y_s \\neq Y_t: P(Y_s|D_s) \\neq P(Y_t|D_t)$\n",
    "\n",
    "Не совпадает пространство лейблов. Пример: датасет лиц людей.\n",
    "- Задача 1: классификация лиц по половому признаку,\n",
    "- Задача 2: классификация лиц по расовому признаку\n",
    "\n",
    "\n",
    "4. Supervised / Unsupervised\n",
    "\n",
    "Есть ли лейблы у $D_T$. Пример: Датасет лиц людей. Есть сеть, которая распознает белых, а мы хотим еще чтобы она распозновала черных с помощью неразмеченных данных.\n",
    "- D_s : размеченные лица по id\n",
    "- D_t : неразмеченные лица людей из другой части мира"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niaePqlZkS-n"
   },
   "source": [
    "#### 2.3 Идеи\n",
    "\n",
    "Когда нейронная сеть обучается, она учится выделять из объектов inter-domain и intra-domain информацию.\n",
    "\n",
    "- inter-domain: расположение элементов на лице, выражения лиц\n",
    "- intra-domain: цвет лица, широта глаз\n",
    "\n",
    "Как перенести только нужные знания сети (inter-domain) на новый домен?\n",
    "\n",
    "__1. Fine-Tuning__\n",
    "\n",
    "__2. Learn two tasks simultaneously__\n",
    "\n",
    "Для Unsupervised learning. Давайте будем с помощью некоторого loss заставлять нашу сеть делать так, чтобы на выходе после нектоторых слоев сети распределение выхода слоя сети для картинки из Source Domain и Target Domain будет одинаковым.\n",
    "\n",
    "<!-- <img src=\"https://drive.google.com/uc?id=1C2B7tiJz51jRB9-2Vq6LmjPzpvuVI9zb\"/> -->\n",
    "<img src=\"./img/simul_1.png\"/>\n",
    "<br>\n",
    "\n",
    "__3. Learn two tasks simultaneously__\n",
    "\n",
    "Архитектурное деление сети на 2 части: 1 часть учит информацию для одного домена, а 2 часть учит информацию для другого.\n",
    "\n",
    "<!-- <img src=\"https://drive.google.com/uc?id=1aAXgNpff3CQPfrXJyB46vadCc_rW5EFk\"/> -->\n",
    "<img src=\"./img/simul_2.png\"/>\n",
    "<br>\n",
    "\n",
    "__4. Extreme Case__\n",
    "\n",
    "У нас есть обученная сеть (black box). Мы будет пытаться сделать выход нашей сети похожим на выход обученной сети (black box) с помощью некоторого loss.\n",
    "\n",
    "<!-- <img src=\"https://drive.google.com/uc?id=1IJfYajmtUfEucnIIBLR6lLK-RkYK-Np4\"/> -->\n",
    "<img src=\"./img/extreme.png\"/>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPj1OUCcg5aSZtmB0I6JyU7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
