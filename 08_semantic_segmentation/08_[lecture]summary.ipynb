{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Лекция 1. Введение  **<a href=\"https://www.youtube.com/watch?v=tIqndofykgc\">YouTube</a>**  **<a href=\"https://vkvideo.ru/video-155161349_456239239?ref_domain=stepik.org\">VK</a>**\n",
    "* Лекция 2. Трюки: Deconvolution, Dilated Convolution  **<a href=\"https://www.youtube.com/watch?v=K73tZxH9nvE\">YouTube</a>**  **<a href=\"https://vkvideo.ru/video-155161349_456239240?ref_domain=stepik.org\">VK</a>**\n",
    "* Лекция 3. Архитектура UNet  **<a href=\"https://www.youtube.com/watch?v=yEuIV5FsRMs\">YouTube</a>**  **<a href=\"https://vkvideo.ru/video-155161349_456239241?ref_domain=stepik.org\">VK</a>**\n",
    "* Семинар 1. Семантическая сегментация **<a href=\"https://www.youtube.com/watch?v=QUYKIC7EmiM&ab_channel=DeepLearningSchool\">YouTube</a>**  **<a href=\"https://vkvideo.ru/video-155161349_456239243?ref_domain=stepik.org\">VK</a>**\n",
    "* Семинар 2. Сегментация изображений с камеры беспилотника **<a href=\"https://www.youtube.com/watch?v=2zdbU7fUId8&ab_channel=%D0%90%D0%BA%D0%B0%D0%B4%D0%B5%D0%BC%D0%B8%D1%8F%D0%B8%D1%81%D0%BA%D1%83%D1%81%D1%81%D1%82%D0%B2%D0%B5%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE%D0%B8%D0%BD%D1%82%D0%B5%D0%BB%D0%BB%D0%B5%D0%BA%D1%82%D0%B0\">YouTube</a>**  **<a href=\"https://vkvideo.ru/video-155161349_456239242?ref_domain=stepik.org\">VK</a>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-h7yCBjzRAV"
   },
   "source": [
    "### 1. Введение\n",
    "\n",
    "#### Постановка задачи\n",
    "- Детекция - находим местоположение объекта на изображении\n",
    "- Сегментация - понять к какому объекту принадлежит пиксель.\n",
    "- Semantic - находим какие пиксели принадлежат конкретному классу объектов.\n",
    "- Instance Segmentation - находим пиксели каждого объекта отдельно (вне зависимости от класса объекта)\n",
    "\n",
    "<img src=\"./img/pws.png\">\n",
    "\n",
    "Мы должны заранее знать классы, на которые будем делить пиксели.\n",
    "- Loss: Pixel-wise Softmax\n",
    "- По сути сегментация это решение задачи классификации для каждого пикселя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Идеи решения: Sliding Windows\n",
    "\n",
    "<img src=\"./img/sliding_window.png\">\n",
    "\n",
    "- Делим картинку на окна (совокупнуть пикселей) и прогоняем их через классификатор (например, ResNet)\n",
    "- Минусы:\n",
    "    - Нужно совершить много вызовов для классификации (вычисления)\n",
    "    - Окна не шарят между собой о частях картинки (по маленькому окошку сложно будет определить, что это кусок коровы)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Идеи решения: Fully-conv network\n",
    "\n",
    "<img src=\"./img/fully-conv.png\" width=800>\n",
    "\n",
    "Минусы:\n",
    "- Большие конволюционные слои, очень много параметров. -> нужно сжимать информацию  о картинке перед построением карты сегментации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Идеи решения: CNN\n",
    "\n",
    "<img src=\"./img/cnn.png\" width=800>\n",
    "\n",
    "- upsampling\n",
    "- Минусы:\n",
    "    - **Upsampling плохо восстанавливает информацию**\n",
    "    - **Downsampling (макспулинг) и большой stride разрушают пространственную информацию (объект может быть в разных местах картинки)**\n",
    "    - **Scale Variability (Вариативность масштаба) - подпроблема 2ого пункта. Объект может быть разных размеров - опять же сбивается местоположение**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cntXwLNoWPRJ"
   },
   "source": [
    "### 2. Трюки: Deconvolution, Dilated Convolution\n",
    "- **Решение проблемы Upsampling восстановления информации -> Deconvolution**\n",
    "- Deconvolution делает feature map побольше.\n",
    "- Как побороть проблема Upsampling -> Deconvolution (Unpooling)\n",
    "- Transposed Convolution - говорить правильно, а не Deconvolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transposed Convolution\n",
    "\n",
    "<img src=\"./img/transposed_convolution.png\" width=800>\n",
    "\n",
    "- это upsampling + convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Виды upsampling\n",
    "\n",
    "- Nearest Neighbours\n",
    "<img src=\"./img/nearest.png\">\n",
    "\n",
    "- Bed of Nails\n",
    "\n",
    "<img src=\"./img/bedon.png\">\n",
    "\n",
    "- Bilinear\n",
    "\n",
    "<img src=\"./img/upsampling_bil.png\">\n",
    "\n",
    "- Max-Unpooling\n",
    "    - нужно знать как мы делали пулинг в начале сети, чтобы сделать восстановление\n",
    "\n",
    "<img src=\"./img/max_unpooling.png\" width=750>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DeConvNet\n",
    "\n",
    "<img src=\"./img/deconvnet.png\" width=800>\n",
    "\n",
    "- Сеть необязательно должна быть симметричной, однако в несимметричной сети применить Max-Unpooling нельзя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dilated Convolution\n",
    "- Решение проблемы **Downsampling и большой stride разрушают пространственную\n",
    "информацию** - Dilated Convolution\n",
    "- Из фильтра 3х3 получили фильтр 5х5\n",
    "- У Dilated convolution больший receptive field (тем самым захватываем больше пространства картинки)\n",
    "- Заменяет stride\n",
    "\n",
    "<img src=\"./img/dilated_conv.png\" width=800>\n",
    "\n",
    "- Заменяет пулинг?\n",
    "\n",
    "<img src=\"./img/di_conv.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-scale Context Aggregator\n",
    "\n",
    "- Решение проблемы **Scale Variability**\n",
    "- Применим к большому объекту Dilated Convolution с большим *R*, а к малому с меньшим *R*\n",
    "\n",
    "<img src=\"./img/msca.png\" width=600>\n",
    "\n",
    "- Но мы не знаем какой R нужно применить -> поэтому делаем агрегатор делаем много параллельных Dilated Convolution с разными R.\n",
    "\n",
    "<img src=\"./img/aggregator.png\" width=800>\n",
    "\n",
    "- Pyramid Pooling Network (распараллелим пулинги)\n",
    "\n",
    "<img src=\"./img/ppn.png\" width=800>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод по трюкам\n",
    "\n",
    "1. Deconvolution\n",
    "2. Dilated Convolutions\n",
    "3. Multi-scale Context Aggregator\n",
    "4. Pyramid Pooling Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8-Oppd1oofH"
   },
   "source": [
    "### 3. Архитектура UNet\n",
    "\n",
    "#### Segmentation Architectures\n",
    "- SegNet (1)\n",
    "- DeepLab v1 (2, 5)\n",
    "- DeepLab v2 (2, 3, 5)\n",
    "- DeepLab v3 (1, 2, 3, 5)\n",
    "- DeepLab v3+ (1, 2, 3, 5)\n",
    "- PSPNet (1, 2, 4)\n",
    "- Mask R-CNN\n",
    "- Это очень старое, лучше ПОЧЕКАТЬ НОВЫЕ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNet\n",
    "\n",
    "<img src=\"./img/unet.png\">\n",
    "\n",
    "- Без Fully-connected слоев\n",
    "- Стрелочки показывают куда течет информация\n",
    "- Важно: есть Copy&concatenate (Skip connection)\n",
    "- Симметричная\n",
    "- Есть BottleNeck, похожа на бутылку\n",
    "- Энкодер сжимает информацию, обработка\n",
    "- Декодер восстанавливает пространственную информацию, а Skip-Connection помогает в этом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overlap-tile strategy\n",
    "\n",
    "- Свертка убивает информацию о границе, поэтому сегментация на выходе может быть получена только для внутренней области изобржения -> В Unete решили это так, что сегментируется только то, что в красной рамки, а для того, что вне рамки - дополняем картинку отзеркаленным отображением (выделено коричневым). То есть зеркалим пограничные кусочки\n",
    "\n",
    "<img src=\"./img/overlap.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNet: Loss\n",
    "\n",
    "- Есть тонкие линии на картинках (границы клеток, например). Проблема: как выделить границы, не относя к объектам?\n",
    "- Для этого в UNet сделали веса. Даем большой loss(выделено красным). Пиксели между клетками - большой loss, большие веса.\n",
    "\n",
    "<img src=\"./img/pwsoftmax.png\" width=750>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMCh775ZgA20IWmCeZ5pgHQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
